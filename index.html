<!DOCTYPE HTML>
<html lang="en">

<head>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-Z1DSNXW1K2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-Z1DSNXW1K2');
  </script>

  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yixing Lao</title>

  <meta name="author" content="Yixing Lao">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <link rel="icon" href="images/favicon/favicon.ico" media="(prefers-color-scheme: light)">
  <link rel="icon" href="images/favicon/favicon.ico" media="(prefers-color-scheme: dark)">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Yixing Lao
                  </p>
                  <p>I'm a PhD Student at <a href="https://www.cs.hku.hk/">The University of Hong Kong</a>,
                    where I work
                    on 3D reconstruction and perception, advised by <a href="https://hszhao.github.io/">Hengshuang
                      Zhao</a>.
                  </p>
                  <p>
                    Previously at Intel, I worked on <a href="https://github.com/isl-org/Open3D">Open3D</a> and <a
                      href="https://arxiv.org/abs/1801.08058">Deep Learning
                      Compilers</a>.
                  </p>
                  <p style="text-align:center">
                    <a>yixing.lao [at] gmail.com</a>
                    &nbsp;/&nbsp;
                    <a href="https://scholar.google.com/citations?user=2w9VSWIAAAAJ&hl=en">Scholar</a>
                    &nbsp;/&nbsp;
                    <a href="https://github.com/yxlao/">GitHub</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:32%;max-width:32%">
                  <a href="images/profile.jpg"><img style="width:100%;max-width:100%;object-fit: cover;
                  border-radius: 50%;" alt="profile photo" src="images/profile.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10" style="display:none;">
            <tbody>
              <tr>
                <td>
                  <h2>News</h2>
                </td>
              </tr>
              <tr>
                <td>
                  <ul>
                    <li>Dec 2023: <a href="https://github.com/yxlao/camtools/releases/tag/v0.1.4">CamTools v0.1.4</a>
                      released.
                    <li>Sept 2023: <a href="https://yxlao.github.io/corres-nerf/">CorresNeRF</a> is accepted to NeurIPS
                      2023.
                  </ul>
                </td>
              </tr>
            </tbody>
          </table> -->

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
            <tbody>
              <tr>
                <td>
                  <h2>Research</h2>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="concerto_stop()" onmouseover="concerto_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id="concerto_image">
                      <a href="https://pointcept.github.io/Concerto/">
                        <img src="images/concerto_hover.jpg" width="160">
                      </a>
                    </div>
                    <a href="https://pointcept.github.io/Concerto/">
                      <img src="images/concerto.jpg" width="160">
                    </a>
                  </div>
                  <script type="text/javascript">
                    function concerto_start() {
                      document.getElementById("concerto_image").style.opacity = "1";
                    }
                    function concerto_stop() {
                      document.getElementById("concerto_image").style.opacity = "0";
                    }
                    concerto_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://pointcept.github.io/Concerto/">
                    <span class="papertitle">Concerto: Joint 2D-3D Self-Supervised Learning Emerges Spatial
                      Representations</span>
                  </a>
                  <br>
                  <a href="https://yjzhang.top/">Yujia Zhang</a>,
                  <a href="https://xywu.me/">Xiaoyang Wu</a>,
                  <strong>Yixing Lao</strong>,
                  <a href="https://chengywang.github.io/">Chengyao Wang</a>,
                  <a href="https://tianzt.github.io/">Zhuotao Tian</a>,
                  <a href="https://winsty.net/">Naiyan Wang</a>,
                  <a href="https://hszhao.github.io/">Hengshuang Zhao</a>
                  <br>
                  <em>NeurIPS</em>, 2025
                  <br>
                  <a href="https://pointcept.github.io/Concerto/">project</a> /
                  <a href="https://github.com/Pointcept/Concerto">code</a> /
                  <a href="https://arxiv.org/abs/2510.23607">paper</a>
                  <p></p>
                  <p>
                    Concerto combines 3D intra-modal self-distillation with 2D-3D cross-modal joint embedding to learn
                    superior spatial representations, setting new SOTA across multiple scene understanding benchmarks.
                  </p>
                </td>
              </tr>

              <tr onmouseout="lit_stop()" onmouseover="lit_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id="lit_image">
                      <a href="https://yxlao.github.io/lit/">
                        <img src="images/lit_hover.gif" width="160">
                      </a>
                    </div>
                    <a href="https://yxlao.github.io/lit/">
                      <img src="images/lit.jpg" width="160">
                    </a>
                  </div>
                  <script type="text/javascript">
                    function lit_start() {
                      document.getElementById("lit_image").style.opacity = "1";
                    }
                    function lit_stop() {
                      document.getElementById("lit_image").style.opacity = "0";
                    }
                    lit_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://yxlao.github.io/lit/">
                    <span class="papertitle">LiT: Unifying LiDAR "Languages" with LiDAR Translator</span>
                  </a>
                  <br>
                  <strong>Yixing Lao</strong>,
                  <a href="https://scholar.google.co.jp/citations?user=1ltylFwAAAAJ">Tao Tang</a>,
                  <a href="https://xywu.me/">Xiaoyang Wu</a>,
                  <a href="https://damo.alibaba.com/labs/intelligent-transportation">Peng Chen</a>,
                  <a href="https://www.yukaicheng.cn/">Kaicheng Yu</a>,
                  <a href="https://hszhao.github.io/">Hengshuang Zhao</a>
                  <br>
                  <em>NeurIPS</em>, 2024
                  <br>
                  <a href="https://yxlao.github.io/lit/">project</a> /
                  <a href="https://github.com/yxlao/lit">code</a> /
                  <a href="https://yxlao.github.io/lit/lit_paper.pdf">paper</a>
                  <p></p>
                  <p>
                    A framework for unifying LiDAR data from different domains into a single target "language", enabling
                    efficient zero-shot and unified domain detection capabilities.
                  </p>
                </td>
              </tr>

              <tr onmouseout="pixelgs_stop()" onmouseover="pixelgs_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id="pixelgs_image">
                      <a href="https://pixelgs.github.io/">
                        <img src="images/pixelgs_hover.jpg" width="160">
                      </a>
                    </div>
                    <a href="https://pixelgs.github.io/">
                      <img src="images/pixelgs.jpg" width="160">
                    </a>
                  </div>
                  <script type="text/javascript">
                    function pixelgs_start() {
                      document.getElementById("pixelgs_image").style.opacity = "1";
                    }
                    function pixelgs_stop() {
                      document.getElementById("pixelgs_image").style.opacity = "0";
                    }
                    pixelgs_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://pixelgs.github.io/">
                    <span class="papertitle">Pixel-GS: Density Control with Pixel-aware Gradient for 3D Gaussian
                      Splatting</span>
                  </a>
                  <br>
                  <a href="https://pixelgs.github.io/">Zheng Zhang</a>,
                  <a href="https://wbhu.github.io/">Wenbo Hu</a>,
                  <strong>Yixing Lao</strong>,
                  <a href="https://tonghe90.github.io/">Tong He</a>,
                  <a href="https://hszhao.github.io/">Hengshuang Zhao</a>
                  <br>
                  <em>ECCV</em>, 2024
                  <br>
                  <a href="https://pixelgs.github.io/">project</a> /
                  <a href="https://github.com/zhengzhang01/Pixel-GS">code</a> /
                  <a href="https://arxiv.org/abs/2403.15530">paper</a>
                  <p></p>
                  <p>
                    Pixel-aware gradients and scaled gradient field can improve 3D Gaussian Splatting density control.
                  </p>
                </td>
              </tr>

              <tr onmouseout="lidarnerf_stop()" onmouseover="lidarnerf_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id="lidarnerf_image">
                      <a href="https://tangtaogo.github.io/lidar-nerf-website/">
                        <img src="images/lidarnerf_hover.jpg" width="160">
                      </a>
                    </div>
                    <a href="https://tangtaogo.github.io/lidar-nerf-website/">
                      <img src="images/lidarnerf.jpg" width="160">
                    </a>
                  </div>
                  <script type="text/javascript">
                    function lidarnerf_start() {
                      document.getElementById("lidarnerf_image").style.opacity = "1";
                    }
                    function lidarnerf_stop() {
                      document.getElementById("lidarnerf_image").style.opacity = "0";
                    }
                    lidarnerf_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://tangtaogo.github.io/lidar-nerf-website/">
                    <span class="papertitle">LiDAR-NeRF: Novel LiDAR View Synthesis via Neural Radiance Fields</span>
                  </a>
                  <br>
                  <a href="https://scholar.google.com.hk/citations?user=1ltylFwAAAAJ&hl=zh-CN&oi=sra">Tao Tang</a>,
                  <a href="https://damo.alibaba.com/labs/intelligent-transportation">Longfei Gao</a>,
                  <a href="https://wanggrun.github.io/">Guangrun Wang</a>,
                  <strong>Yixing Lao</strong>,
                  <a href="https://damo.alibaba.com/labs/intelligent-transportation">Peng Chen</a>,
                  <a href="https://hszhao.github.io/">Hengshuang Zhao</a>,
                  <a href="https://damo.alibaba.com/labs/intelligent-transportation">Dayang Hao</a>,
                  <a href="https://scholar.google.com/citations?user=voxznZAAAAAJ">Xiaodan Liang</a>,
                  <a href="https://scholar.google.com/citations?user=n-B0jr4AAAAJ">Mathieu Salzmann</a>,
                  <a href="https://scholar.google.com.hk/citations?user=Jtmq_m0AAAAJ&hl=zh-CN&oi=sra">Kaicheng Yu</a>
                  <br>
                  <em>ACM Multimedia</em>, 2024
                  <br>
                  <a href="https://github.com/tangtaogo/lidar-nerf/tree/main">code</a> /
                  <a href="https://arxiv.org/abs/2304.10406">paper</a> /
                  <a href="https://youtu.be/YX4LX025mZQ">video</a>
                  <p></p>
                  <p>
                    LiDAR novel-view synthesis with neural radiance fields, enhancing realism for 3D scene
                    reconstructions.
                  </p>
                </td>
              </tr>

              <tr onmouseout="owl_stop()" onmouseover="owl_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id="owl_image">
                      <a href="">
                        <img src="images/owl_hover.jpg" width="160">
                      </a>
                    </div>
                    <a href="">
                      <img src="images/owl.jpg" width="160">
                    </a>
                  </div>
                  <script type="text/javascript">
                    function owl_start() {
                      document.getElementById("owl_image").style.opacity = "1";
                    }
                    function owl_stop() {
                      document.getElementById("owl_image").style.opacity = "0";
                    }
                    owl_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://yxlao.github.io">
                    <span class="papertitle">Objects with Lighting: A Real-World Dataset for Evaluating Reconstruction
                      and Rendering for Object Relighting</span>
                  </a>
                  <br>
                  <a href="https://scholar.google.de/citations?user=QGlp5ywAAAAJ&hl=en">Benjamin Ummenhofer</a>,
                  <a href="https://scholar.google.co.in/citations?user=lgzPww0AAAAJ&hl=en">Sanskar Agrawal</a>,
                  <a href="https://www.linkedin.com/in/rene-sepulveda-48a3a25/">Rene Sepulveda</a>,
                  <strong>Yixing Lao</strong>,
                  <a href="https://kai-46.github.io/website/">Kai Zhang</a>,
                  <a href="https://tianhang-cheng.github.io/">Tianhang Cheng</a>,
                  <a href="http://www.stephanrichter.org/">Stephan R. Richter</a>,
                  <a href="https://shenlong.web.illinois.edu/">Shenlong Wang</a>,
                  <a href="https://germanros.net/">German Ros</a>
                  <br>
                  <em>3DV</em>, 2024
                  <br>
                  <a href="https://github.com/isl-org/objects-with-lighting">code</a> /
                  <a href="https://arxiv.org/abs/2401.09126">paper</a>
                  <p></p>
                  <p>
                    A real-world dataset for evaluating inverse rendering methods in object
                    relighting, allowing for a comprehensive analysis of relighting performance.
                  </p>
                </td>
              </tr>

              <tr onmouseout="corresnerf_stop()" onmouseover="corresnerf_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id="corresnerf_image">
                      <a href="https://yxlao.github.io/corres-nerf/">
                        <img src="images/corresnerf_hover.jpg" width="160">
                      </a>
                    </div>
                    <a href="https://yxlao.github.io/corres-nerf/">
                      <img src="images/corresnerf.jpg" width="160">
                    </a>
                  </div>
                  <script type="text/javascript">
                    function corresnerf_start() {
                      document.getElementById("corresnerf_image").style.opacity = "1";
                    }
                    function corresnerf_stop() {
                      document.getElementById("corresnerf_image").style.opacity = "0";
                    }
                    corresnerf_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://yxlao.github.io/corres-nerf/">
                    <span class="papertitle">CorresNeRF: Image Correspondence Priors for Neural Radiance Fields</span>
                  </a>
                  <br>
                  <strong>Yixing Lao</strong>,
                  <a href="https://xiaogang00.github.io/">Xiaogang Xu</a>,
                  <a href="https://zhipengcai.github.io/">Zhipeng Cai</a>,
                  <a href="https://xh-liu.github.io/">Xihui Liu</a>,
                  <a href="https://hszhao.github.io/">Hengshuang Zhao</a>
                  <br>
                  <em>NeurIPS</em>, 2023
                  <br>
                  <a href="https://yxlao.github.io/corres-nerf/">project</a> /
                  <a href="https://github.com/yxlao/corres-nerf/">code</a> /
                  <a href="https://arxiv.org/abs/2312.06642">paper</a>
                  <p></p>
                  <p>
                    Utilizing image correspondences as NeRF priors improves novel view synthesis and surface
                    reconstruction.
                  </p>
                </td>
              </tr>

              <tr onmouseout="ptv2_stop()" onmouseover="ptv2_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id="ptv2_image">
                      <a href="https://github.com/Pointcept/PointTransformerV2">
                        <img src="images/ptv2_hover.jpg" width="160">
                      </a>
                    </div>
                    <a href="href=" https://github.com/Pointcept/PointTransformerV2">
                      <img src="images/ptv2.jpg" width="160">
                    </a>
                  </div>
                  <script type="text/javascript">
                    function ptv2_start() {
                      document.getElementById("ptv2_image").style.opacity = "1";
                    }
                    function ptv2_stop() {
                      document.getElementById("ptv2_image").style.opacity = "0";
                    }
                    ptv2_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://github.com/Pointcept/PointTransformerV2">
                    <span class="papertitle">Point Transformer V2: Grouped Vector Attention and Partition-based
                      Pooling</span>
                  </a>
                  <br>
                  <a href="https://xywu.me/">Xiaoyang Wu</a>,
                  <strong>Yixing Lao</strong>,
                  <a href="https://llijiang.github.io/">Li Jiang</a>,
                  <a href="https://xh-liu.github.io/">Xihui Liu</a>,
                  <a href="https://hszhao.github.io/">Hengshuang Zhao</a>
                  <br>
                  <em>NeurIPS</em>, 2022
                  <br>
                  <a href="https://github.com/Pointcept/PointTransformerV2">code</a> /
                  <a href="https://arxiv.org/abs/2210.05666">paper</a>
                  <p></p>
                  <p>
                    Grouped Vector Attention and Partition-based Pooling make transformers effective and efficient for
                    point cloud recognition.
                  </p>
                </td>
              </tr>

              <tr onmouseout="ash_stop()" onmouseover="ash_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id="ash_image">
                      <a href="http://www.open3d.org/docs/latest/tutorial/t_reconstruction_system/index.html">
                        <img src="images/ash_hover.jpg" width="160">
                      </a>
                    </div>
                    <a href="http://www.open3d.org/docs/latest/tutorial/t_reconstruction_system/index.html">
                      <img src="images/ash.jpg" width="160">
                    </a>
                  </div>
                  <script type="text/javascript">
                    function ash_start() {
                      document.getElementById("ash_image").style.opacity = "1";
                    }
                    function ash_stop() {
                      document.getElementById("ash_image").style.opacity = "0";
                    }
                    ash_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2110.00511">
                    <span class="papertitle">ASH: A Modern Framework for Parallel Spatial Hashing in 3D
                      Perception</span>
                  </a>
                  <br>
                  <a href="https://dongwei.info">Wei Dong</a>,
                  <strong>Yixing Lao</strong>,
                  <a href="https://www.cs.cmu.edu/~kaess/">Michael Kaess</a>,
                  <a href="https://vladlen.info/">Vladlen Koltun</a>
                  <br>
                  <em>TPAMI</em>, 2022
                  <br>
                  <a href="http://www.open3d.org/docs/latest/tutorial/t_reconstruction_system/index.html">code</a> /
                  <a href="https://arxiv.org/abs/2110.00511">paper</a>
                  <p></p>
                  <p>
                    A high-performance spatial hashing framework on GPU, demonstrating superior performance with fewer
                    lines of code on various tasks such as volumetric reconstruction, non-rigid registration, and
                    spatially varying appearance refinement.
                  </p>
                </td>
              </tr>


            </tbody>
          </table>

          <br><br>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
            <tbody>
              <tr>
                <td>
                  <h2>Software</h2>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="camtools_stop()" onmouseover="camtools_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id="camtools_image">
                      <a href="https://github.com/yxlao/camtools">
                        <img src="images/camtools_hover.jpg" width="160">
                      </a>
                    </div>
                    <a href="https://github.com/yxlao/camtools">
                      <img src="images/camtools.jpg" width="160">
                    </a>
                  </div>
                  <script type="text/javascript">
                    function camtools_start() {
                      document.getElementById("camtools_image").style.opacity = "1";
                    }
                    function camtools_stop() {
                      document.getElementById("camtools_image").style.opacity = "0";
                    }
                    camtools_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://github.com/yxlao/camtools">
                    <span class="papertitle">CamTools: Camera Tools for Computer
                      Vision</span>
                  </a>
                  <br>
                  <a href="https://github.com/yxlao/camtools">project</a>
                  /
                  <a href="https://github.com/yxlao/camtools">code</a>
                  <p></p>
                  <p>
                    A collection of tools for handling cameras in computer
                    vision. Plot, convert, project, ray cast, and do more with your cameras. A must-have for debugging
                    NeRFs and 3D reconstruction.
                  </p>
                </td>
              </tr>

              <tr onmouseout="open3d_stop()" onmouseover="open3d_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id="open3d_image">
                      <a href="https://github.com/isl-org/Open3D">
                        <img src="images/open3d_hover.jpg" width="160">
                      </a>
                    </div>
                    <a href="https://github.com/isl-org/Open3D">
                      <img src="images/open3d.jpg" width="160">
                    </a>
                  </div>
                  <script type="text/javascript">
                    function open3d_start() {
                      document.getElementById("open3d_image").style.opacity = "1";
                    }
                    function open3d_stop() {
                      document.getElementById("open3d_image").style.opacity = "0";
                    }
                    open3d_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://github.com/isl-org/Open3D">
                    <span class="papertitle">Open3D: A Modern Library for 3D
                      Data Processing</span>
                  </a>
                  <br>
                  <a href="http://www.open3d.org">project</a>
                  /
                  <a href="https://github.com/isl-org/Open3D">code</a>
                  <p></p>
                  <p>
                    The leading open-source library for 3D processing with 400K+ monthly downloads from PyPI. Open3D
                    exposes a set of carefully selected data structures and algorithms in both C++ and Python.
                  </p>
                </td>
              </tr>

            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
            <tr>
              <td>
                <br>
                <p align="right">
                  <font size="2">
                    Check out the <a href="https://github.com/yxlao/yxlao.github.io">source code</a> for this website.
                    Yep, it's yet another <a href="https://github.com/jonbarron/website">Jon Barron</a> site.
                    <br>
                    Last updated Oct 2024.
                  </font>
                </p>
              </td>
            </tr>
          </table>

        </td>
      </tr>
  </table>
</body>

</html>
